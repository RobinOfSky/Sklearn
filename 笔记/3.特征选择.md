#### 特征选择
1. 数据处理完之后，要选择有意义的特征输入机器学习的算法和模型进行训练。通常从两个方面考虑来选择特征：
- 特征是否发散：如果一个特征不发散，例如方差方差接近于0,也就是说这个特征在一个数据集上是没有差异的，这个特征对于样本的区分并没有什么用。
- 特征与目标的相关性：这个比较显见，与目标值相见度高的特征，应当优先选择，。除方差外，本文介绍的其他方法均从相关性考虑
2. 更具特征选择的形式可以将特征选择方法分为三种：
- Filter：过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值灹选择阈值的个数，选择特征。
- Wrapper:包装法，根据目标函数，每次选择若干特征，或者是排除若干特征。
- Embedded:嵌入法，先试用某些机器学习的算法和模型进行训练，得到的各个特征的权值系数，根据系数从大到小选择特征，类似于Filter，但是通过训练来确定特征的优劣。
3. Filter：
- 方差选择法：计算各个特征的方差值，再根据阈值选择出方差大于阈值的特征。VarianceThreshold
- 相关系数法：根据k个最高分数选择功能。k表示可以要选择的特征数，sorce_func：